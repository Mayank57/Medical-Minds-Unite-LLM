The field of medicine is witnessing a surge in the application of Large Language Models (LLMs). Trained on vast medical data and literature, these AI systems showcase impressive potential, particularly in facilitating question-answering. LLMs can form the basis of applications, such as virtual medical assistants having the capability of answering complex patient queries, simplifying medical concepts, and providing preliminary diagnoses based on symptoms. While LLMs do possess these capabilities, most of them require to be trained on a huge corpus of data and are proprietary, examples of such models include GPT and BARD. To mitigate these issues with current LLMs, we are proposing two techniques, Model Ensembling and a Mixture of Experts. These two methods have proven to improve the performance of weaker open-source models, empowering them to perform at the level of strong proprietary models.
